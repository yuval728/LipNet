{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e386d24-1e56-464f-991b-56fc0fac49b1",
    "_uuid": "a8a83586-aad4-452d-8ee8-955bde72e9ac",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:26.521174Z",
     "iopub.status.busy": "2024-11-01T05:21:26.520909Z",
     "iopub.status.idle": "2024-11-01T05:21:31.227777Z",
     "shell.execute_reply": "2024-11-01T05:21:31.226962Z",
     "shell.execute_reply.started": "2024-11-01T05:21:26.521143Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "44425235-6270-432c-8679-4dc476b496e8",
    "_uuid": "98aeb724-f7df-43ab-b37d-ea30169a8ad9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:31.229585Z",
     "iopub.status.busy": "2024-11-01T05:21:31.229173Z",
     "iopub.status.idle": "2024-11-01T05:21:31.267003Z",
     "shell.execute_reply": "2024-11-01T05:21:31.265868Z",
     "shell.execute_reply.started": "2024-11-01T05:21:31.229551Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eacbfaca-5c05-4e71-a5d4-a4878f64cf5a",
    "_uuid": "32581999-f02a-4d5d-8e97-57f93328db67",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:31.268435Z",
     "iopub.status.busy": "2024-11-01T05:21:31.268138Z",
     "iopub.status.idle": "2024-11-01T05:21:31.280436Z",
     "shell.execute_reply": "2024-11-01T05:21:31.279642Z",
     "shell.execute_reply.started": "2024-11-01T05:21:31.268403Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "\n",
    "def get_word2idx_idx2word(vocab):\n",
    "    word2idx = {word: idx+1 for idx, word in enumerate(vocab)}\n",
    "    word2idx['<PAD>'] = 0 #len(word2idx)\n",
    "    # word2idx['<START>'] = len(word2idx)\n",
    "    # word2idx['<END>'] = len(word2idx)\n",
    "    # word2idx['<UNK>'] = len(word2idx)\n",
    "    idx2word = {idx+1: word for idx, word in enumerate(vocab)}\n",
    "    idx2word[0] = '<PAD>'\n",
    "    # idx2word[len(idx2word)] = '<UNK>'\n",
    "    return word2idx, idx2word\n",
    "\n",
    "def char_to_num(texts, word2idx):\n",
    "    return [word2idx[char] for char in texts if char in word2idx]\n",
    "\n",
    "def num_to_char(nums, idx2word):\n",
    "    return [idx2word.get(num, '') for num in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aebac524-4ba4-4b05-961b-2962d9eb37ac",
    "_uuid": "15e76781-270b-4dbf-940e-7bc42c021c84",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:31.282625Z",
     "iopub.status.busy": "2024-11-01T05:21:31.282316Z",
     "iopub.status.idle": "2024-11-01T05:21:31.299220Z",
     "shell.execute_reply": "2024-11-01T05:21:31.298275Z",
     "shell.execute_reply.started": "2024-11-01T05:21:31.282592Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LipDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, label_dir: str, vocab: list, word2idx: dict, idx2word: dict, transform=transforms.ToTensor()) -> None:\n",
    "        self.data_dir = data_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.data = os.listdir(data_dir)\n",
    "        self.data.remove('sgib8n.mpg')\n",
    "        self.label = os.listdir(label_dir)\n",
    "        self.vocab = vocab\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            data_path = os.path.join(self.data_dir, self.data[idx])\n",
    "            label_file = self.data[idx].split(\".\")[0] + \".align\"\n",
    "            label_path = os.path.join(self.label_dir, label_file)\n",
    "\n",
    "            assert os.path.exists(data_path), f\"Data path {data_path} does not exist\"\n",
    "            assert os.path.exists(label_path), f\"Label path {label_path} does not exist\"\n",
    "\n",
    "            assert (\n",
    "                data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "                == label_path.split(\"/\")[-1].split(\".\")[0]\n",
    "            ), \"Data and label file names do not match\"\n",
    "\n",
    "            frames = self.load_video(data_path)\n",
    "            if frames is None:\n",
    "                print(idx)\n",
    "\n",
    "            label = self.load_alignment(label_path)\n",
    "            \n",
    "#             print(idx, label_file)\n",
    "\n",
    "            return frames, label\n",
    "        except Exception as e:\n",
    "            print(idx, e)\n",
    "\n",
    "    def load_video(self, path: str) -> torch.Tensor:\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frames = []\n",
    "        for i in range(num_frames):\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            frame = frame[\n",
    "                190:236, 80:220, :\n",
    "            ]  # TODO: Make it dynamic using dlib  # Take only the lip part of the frame\n",
    "            \n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "        frames = torch.stack(frames)\n",
    "        \n",
    "        std = torch.std(frames)\n",
    "        mean = torch.mean(frames)\n",
    "#         print(std, mean)\n",
    "        frames = (frames - mean) / std # Normalize the frames (z-score normalization\n",
    "\n",
    "        return frames # (T, H, W, C)\n",
    "    \n",
    "    \n",
    "    def load_alignment(self, path: str) -> torch.Tensor:\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.readlines() \n",
    "        tokens = []\n",
    "        for line in lines:\n",
    "            line = line.split()\n",
    "            if line[2] != \"sil\":\n",
    "                # tokens = [*tokens, ' ',line[2]]\n",
    "                tokens.append(' ')\n",
    "                tokens.extend(list(line[2]))  \n",
    "\n",
    "        token_nums = char_to_num(tokens, self.word2idx)\n",
    "\n",
    "        \n",
    "        return torch.tensor(token_nums[1:], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88c053ed-e1e4-4454-ade5-5095b05518d9",
    "_uuid": "7b55be90-5d82-41c2-b4b4-f4be5e22725a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:31.301020Z",
     "iopub.status.busy": "2024-11-01T05:21:31.300417Z",
     "iopub.status.idle": "2024-11-01T05:21:32.116870Z",
     "shell.execute_reply": "2024-11-01T05:21:32.115720Z",
     "shell.execute_reply.started": "2024-11-01T05:21:31.300978Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = get_word2idx_idx2word(vocab)\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),                     \n",
    "        transforms.ToTensor(),       \n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "#         transforms.Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229]),\n",
    "#         transforms.Normalize(mean=[0.7136, 0.4906, 0.3283],\n",
    "#                 std=[0.113855171, 0.107828568, 0.0917060521]),\n",
    "         \n",
    "    ]\n",
    ")\n",
    "\n",
    "data_dir = \"/kaggle/input/lipnet-videos/s1\"\n",
    "label_dir = \"/kaggle/input/lipnet-videos/alignments/s1\"\n",
    "\n",
    "dataset = LipDataset(data_dir, label_dir, transform=data_transform, vocab=vocab, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5392bde2-36e2-498c-a859-2c5550ce396d",
    "_uuid": "df44961e-eae2-4f96-a25c-20b75916cb1b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.118675Z",
     "iopub.status.busy": "2024-11-01T05:21:32.118221Z",
     "iopub.status.idle": "2024-11-01T05:21:32.126821Z",
     "shell.execute_reply": "2024-11-01T05:21:32.125501Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.118615Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch, pad_value=0):\n",
    "    frames, labels = zip(*batch)\n",
    "\n",
    "    # Pad the frames to the same length\n",
    "    max_len = max([f.shape[0] for f in frames])\n",
    "    frames = [torch.nn.functional.pad(input=f, pad=(0, 0, 0, 0, 0, 0, 0, max_len - f.shape[0]), mode='constant', value=0) for f in frames] \n",
    "    \n",
    "    # Pad the labels to the same length\n",
    "    max_len = max([l.shape[0] for l in labels])  # noqa: E741\n",
    "    labels = [torch.nn.functional.pad(input=l, pad=(0, max_len - l.shape[0]), mode='constant', value=pad_value) for l in labels]  # noqa: E741\n",
    "    \n",
    "    return torch.stack(frames), torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6474634e-5963-4620-9c23-119fdda5d55f",
    "_uuid": "28a83ad7-8762-45ad-b8b8-f66a1ed6273a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.128535Z",
     "iopub.status.busy": "2024-11-01T05:21:32.128167Z",
     "iopub.status.idle": "2024-11-01T05:21:32.366967Z",
     "shell.execute_reply": "2024-11-01T05:21:32.366009Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.128501Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "frames, label = dataset[0]\n",
    "print(frames.shape, label, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "962ef637-8fd4-446a-a766-ca7c6ff3dd1b",
    "_uuid": "b3cbbad5-d670-438f-a294-d6c949b95c29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.368757Z",
     "iopub.status.busy": "2024-11-01T05:21:32.368211Z",
     "iopub.status.idle": "2024-11-01T05:21:32.629916Z",
     "shell.execute_reply": "2024-11-01T05:21:32.629025Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.368713Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(frames[23].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6611359-ae16-4899-b465-676171ed77a2",
    "_uuid": "50611a77-32e7-4450-9c88-d6d37e3d3cf3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.631381Z",
     "iopub.status.busy": "2024-11-01T05:21:32.631091Z",
     "iopub.status.idle": "2024-11-01T05:21:32.636174Z",
     "shell.execute_reply": "2024-11-01T05:21:32.635302Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.631349Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(''.join(num_to_char(label.tolist(), idx2word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ab74175-fc27-44b9-9ae5-22fee97ba14d",
    "_uuid": "3db6bd3c-5f3b-4d8a-a946-015ee3d6043c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.640681Z",
     "iopub.status.busy": "2024-11-01T05:21:32.640323Z",
     "iopub.status.idle": "2024-11-01T05:21:32.649373Z",
     "shell.execute_reply": "2024-11-01T05:21:32.648504Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.640648Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, val_split=0.2):\n",
    "    n_val = int(len(dataset) * val_split)\n",
    "    n_train = len(dataset) - n_val\n",
    "    return torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(dataset)\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.650892Z",
     "iopub.status.busy": "2024-11-01T05:21:32.650543Z",
     "iopub.status.idle": "2024-11-01T05:21:32.656977Z",
     "shell.execute_reply": "2024-11-01T05:21:32.656104Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.650850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=False, collate_fn=collate_fn, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "82d47a4c-86f4-4ae7-884d-a444c3925066",
    "_uuid": "4d94a07b-23a7-4ad8-80db-6961ad7782d3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.658333Z",
     "iopub.status.busy": "2024-11-01T05:21:32.658051Z",
     "iopub.status.idle": "2024-11-01T05:21:32.676168Z",
     "shell.execute_reply": "2024-11-01T05:21:32.675324Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.658302Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LipNet(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size=128, dropout=0.5, input_channels=1):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=input_channels, out_channels=128, kernel_size=(3,3,3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            # nn.Dropout3d(dropout),\n",
    "            \n",
    "            nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(3,3,3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            # nn.Dropout3d(dropout),\n",
    "            \n",
    "            nn.Conv3d(in_channels=256, out_channels=75, kernel_size=(3,3,3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(75),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            # nn.Dropout3d(dropout)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=75 * (46 // 8) * (140 // 8), hidden_size=hidden_size,\n",
    "                             num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size=256, hidden_size=hidden_size,\n",
    "                             num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size+1)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "#         print(x.shape)\n",
    "        x = x.permute(2, 0, 1, 3, 4).contiguous()\n",
    "#         print(x.shape)\n",
    "        # (B, C, T, H, W)->(T, B, C*H*W)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        self.lstm1.flatten_parameters()\n",
    "        self.lstm2.flatten_parameters()\n",
    "        \n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = x.permute(1, 0, 2).contiguous()\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        print('Model weights initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e880a1f-e84a-4d4b-9a66-74c23d167413",
    "_uuid": "94142783-9eee-4833-bdd4-97900800b284",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:32.677906Z",
     "iopub.status.busy": "2024-11-01T05:21:32.677287Z",
     "iopub.status.idle": "2024-11-01T05:21:33.578742Z",
     "shell.execute_reply": "2024-11-01T05:21:33.577925Z",
     "shell.execute_reply.started": "2024-11-01T05:21:32.677863Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " # deterministic training\n",
    "seed = 86\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "model = LipNet(vocab_size=len(word2idx), input_size=75, input_channels=1).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe9ea195-7f70-45eb-b79b-e2870d650d73",
    "_uuid": "29007d49-d8bf-4aef-b724-ce4de85e1b7b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:33.580067Z",
     "iopub.status.busy": "2024-11-01T05:21:33.579760Z",
     "iopub.status.idle": "2024-11-01T05:21:33.584469Z",
     "shell.execute_reply": "2024-11-01T05:21:33.583498Z",
     "shell.execute_reply.started": "2024-11-01T05:21:33.580034Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# output = model(frames.permute(0,2,1,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45d43a1c-1edd-4aa1-bbfd-81c2999e5faf",
    "_uuid": "bded76dd-52e6-4627-b5b2-7cb2d73a6c2d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:33.586072Z",
     "iopub.status.busy": "2024-11-01T05:21:33.585710Z",
     "iopub.status.idle": "2024-11-01T05:21:33.594597Z",
     "shell.execute_reply": "2024-11-01T05:21:33.593859Z",
     "shell.execute_reply.started": "2024-11-01T05:21:33.586031Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ctc_greedy_decode(y_pred, idx2word, blank_index=40):\n",
    "    # y_pred: tensor of shape (max_time_steps, batch_size, num_classes)\n",
    "    \n",
    "    # Get the predicted class index for each time step\n",
    "    y_pred_softmax = F.softmax(y_pred, dim=2)\n",
    "    max_indices = torch.argmax(y_pred_softmax, dim=2)  # Shape: (max_time_steps, batch_size)\n",
    "\n",
    "    # Decode sequences\n",
    "    decoded_sequences = []\n",
    "    for seq in max_indices.permute(1, 0):  # Shape: (batch_size, max_time_steps)\n",
    "        decoded_seq = []\n",
    "        prev_index = -1\n",
    "        for index in seq:\n",
    "            # Skip duplicates and blank\n",
    "            if index != blank_index and index != prev_index:\n",
    "                decoded_seq.append(index.item())\n",
    "                prev_index = index.item()\n",
    "#         print(num_to_char(decoded_seq, idx2word))\n",
    "        decoded_sequences.append(decoded_seq)\n",
    "    print(decoded_sequences)\n",
    "    return decoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3eaeb12-60a9-422d-ac0f-47356a32abd2",
    "_uuid": "61b1a3a4-adf3-4a4d-89b8-6427e72c2806",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:33.596571Z",
     "iopub.status.busy": "2024-11-01T05:21:33.595793Z",
     "iopub.status.idle": "2024-11-01T05:21:33.604631Z",
     "shell.execute_reply": "2024-11-01T05:21:33.603856Z",
     "shell.execute_reply.started": "2024-11-01T05:21:33.596538Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss(reduction='mean', zero_infinity=True, blank = 40)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "lambda_lr = lambda epoch: 1.0 if epoch < 40 else math.exp(-0.1 * (epoch - 39))\n",
    "# Use LambdaLR with your custom schedule\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c558c558-c41d-4e23-8523-1c44d68e4b15",
    "_uuid": "54df18ad-f245-499e-a816-39bf912842b2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:33.606030Z",
     "iopub.status.busy": "2024-11-01T05:21:33.605737Z",
     "iopub.status.idle": "2024-11-01T05:21:33.618723Z",
     "shell.execute_reply": "2024-11-01T05:21:33.617859Z",
     "shell.execute_reply.started": "2024-11-01T05:21:33.606000Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ctc_loss_fn(y_true, y_pred, ctc_loss):\n",
    "    batch_len = y_true.size(0)  # Number of sequences in the batch\n",
    "    input_length = y_pred.size(1)  # Time steps per batch sequence\n",
    "    \n",
    "    # Correctly create input_lengths with shape (batch_len,)\n",
    "    input_lengths = torch.full((batch_len,), input_length, dtype=torch.int32)\n",
    "\n",
    "    # Calculate target lengths based on actual lengths of sequences in y_true\n",
    "    target_lengths = torch.tensor([len(seq[seq != 0]) for seq in y_true], dtype=torch.int32)\n",
    "\n",
    "    # print(input_lengths, target_lengths, y_true.size(), y_pred.shape)\n",
    "    \n",
    "    y_true_flattened = y_true[y_true != 0].view(-1)  # Flattening while ignoring padding\n",
    "    \n",
    "    y_preds_logits = y_pred.permute(1,0,2).log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "    loss = ctc_loss(y_preds_logits, y_true_flattened, input_lengths, target_lengths)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_path, is_best=False):\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(checkpoint_path)):\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f'Checkpoint saved at {checkpoint_path}')\n",
    "    \n",
    "    if is_best:\n",
    "        best_path = checkpoint_path.replace('.pt', '_best.pt')\n",
    "        torch.save(checkpoint, best_path)\n",
    "        print(f'Best model saved at {best_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "718e0f51-2d61-4ea2-afcf-0e46a2111bf0",
    "_uuid": "1055163b-99ba-460f-aa3e-bbe8fee56ab3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:33.620751Z",
     "iopub.status.busy": "2024-11-01T05:21:33.619857Z",
     "iopub.status.idle": "2024-11-01T05:21:33.632257Z",
     "shell.execute_reply": "2024-11-01T05:21:33.631412Z",
     "shell.execute_reply.started": "2024-11-01T05:21:33.620702Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device, lr_scheduler,print_every=40):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, (frames, labels) in enumerate(dataloader):\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(frames.permute(0,2,1,3,4))\n",
    "        \n",
    "\n",
    "        loss = ctc_loss_fn(labels, output, criterion)\n",
    "         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        frames, labels = frames.cpu(), labels.cpu()\n",
    "        \n",
    "        if (i+1) % print_every == 0:\n",
    "            ctc_greedy_decode(output.clone(), idx2word)\n",
    "            print(f'Batch {i+1}/{len(dataloader)} - Loss: {loss.item()}')\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    print(f'Learning rate: {lr_scheduler.get_last_lr()}')\n",
    "            \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, print_every=10):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for i, (frames, labels) in enumerate(dataloader):\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "            \n",
    "            output = model(frames.permute(0,2,1,3,4))\n",
    "             \n",
    "            loss = ctc_loss_fn(labels, output, criterion)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            frames, labels = frames.cpu(), labels.cpu()\n",
    "            \n",
    "            if (i+1) % print_every == 0:\n",
    "                ctc_greedy_decode(output.clone(), idx2word)\n",
    "                print(f'Batch {i+1}/{len(dataloader)} - Loss: {loss.item()}')\n",
    "                \n",
    "            \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "809ff5d3-3304-429f-b2fd-63a9aa97ca36",
    "_uuid": "f9c0f3eb-f733-40f1-96ba-6fc469bbe628",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:21:33.633820Z",
     "iopub.status.busy": "2024-11-01T05:21:33.633515Z",
     "iopub.status.idle": "2024-11-01T05:23:32.312215Z",
     "shell.execute_reply": "2024-11-01T05:23:32.310941Z",
     "shell.execute_reply.started": "2024-11-01T05:21:33.633790Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, lr_scheduler, num_epochs, device, checkpoint_path='/kaggle/working/check.pt'):\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs}')\n",
    "        \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device, lr_scheduler)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        \n",
    "        val_loss = evaluate(model, val_dataloader, criterion, device)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss} - Val Loss: {val_loss}')\n",
    "        \n",
    "        save_checkpoint(model, optimizer, epoch, val_loss, checkpoint_path, False)\n",
    "        \n",
    "        \n",
    "    return loss_history\n",
    "\n",
    "num_epochs = 100\n",
    "loss_history = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, lr_scheduler , num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cf3a5ebe-2fd4-4876-9c06-3795788cfa5b",
    "_uuid": "5ddf58ec-dce8-4d18-9e99-fe172732ac95",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:23:32.314040Z",
     "iopub.status.busy": "2024-11-01T05:23:32.313688Z",
     "iopub.status.idle": "2024-11-01T05:23:32.386889Z",
     "shell.execute_reply": "2024-11-01T05:23:32.386075Z",
     "shell.execute_reply.started": "2024-11-01T05:23:32.314002Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "frames, labels = train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "63552a8f-5ac2-4a7d-a3e9-7531e5f18b4c",
    "_uuid": "79945823-c050-46f8-8ea5-564c55723931",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:23:32.388474Z",
     "iopub.status.busy": "2024-11-01T05:23:32.388072Z",
     "iopub.status.idle": "2024-11-01T05:23:32.403795Z",
     "shell.execute_reply": "2024-11-01T05:23:32.403015Z",
     "shell.execute_reply.started": "2024-11-01T05:23:32.388422Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output = model(frames.unsqueeze(0).permute(0,2,1,3,4).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03636e06-8395-43b1-b5da-aa20b8b11c31",
    "_uuid": "adf116d0-e403-478e-beb6-3244fc0d1e29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:23:32.405207Z",
     "iopub.status.busy": "2024-11-01T05:23:32.404912Z",
     "iopub.status.idle": "2024-11-01T05:23:32.442762Z",
     "shell.execute_reply": "2024-11-01T05:23:32.441896Z",
     "shell.execute_reply.started": "2024-11-01T05:23:32.405175Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# output = output.permute(1, 0, 2)\n",
    "print('Output shape:', output.shape)\n",
    "ctcts = ctc_greedy_decode(output, idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55e8bbb6-7cd7-44b4-b558-7fa09058659c",
    "_uuid": "9d0b6b8a-1029-45fd-8e10-83e94cbf57bc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-01T05:23:32.444502Z",
     "iopub.status.busy": "2024-11-01T05:23:32.444133Z",
     "iopub.status.idle": "2024-11-01T05:23:32.450049Z",
     "shell.execute_reply": "2024-11-01T05:23:32.449069Z",
     "shell.execute_reply.started": "2024-11-01T05:23:32.444443Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in ctcts:\n",
    "    print(num_to_char(i, idx2word))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5966387,
     "sourceId": 9746086,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
