{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e386d24-1e56-464f-991b-56fc0fac49b1",
    "_uuid": "a8a83586-aad4-452d-8ee8-955bde72e9ac",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:36.989963Z",
     "iopub.status.busy": "2024-11-18T07:38:36.989628Z",
     "iopub.status.idle": "2024-11-18T07:38:41.554109Z",
     "shell.execute_reply": "2024-11-18T07:38:41.553325Z",
     "shell.execute_reply.started": "2024-11-18T07:38:36.989928Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "44425235-6270-432c-8679-4dc476b496e8",
    "_uuid": "98aeb724-f7df-43ab-b37d-ea30169a8ad9",
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.556603Z",
     "iopub.status.busy": "2024-11-18T07:38:41.556084Z",
     "iopub.status.idle": "2024-11-18T07:38:41.595860Z",
     "shell.execute_reply": "2024-11-18T07:38:41.594876Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.556557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eacbfaca-5c05-4e71-a5d4-a4878f64cf5a",
    "_uuid": "32581999-f02a-4d5d-8e97-57f93328db67",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.597406Z",
     "iopub.status.busy": "2024-11-18T07:38:41.597056Z",
     "iopub.status.idle": "2024-11-18T07:38:41.604991Z",
     "shell.execute_reply": "2024-11-18T07:38:41.604072Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.597363Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz \"]\n",
    "\n",
    "def get_word2idx_idx2word(vocab):\n",
    "    word2idx = {word: idx+1 for idx, word in enumerate(vocab)}\n",
    "    word2idx[''] = 0\n",
    "\n",
    "    idx2word = {idx+1: word for idx, word in enumerate(vocab)}\n",
    "    idx2word[0] = ''\n",
    "    return word2idx, idx2word\n",
    "\n",
    "def char_to_num(texts, word2idx):\n",
    "    return [word2idx[char] for char in texts if char in word2idx]\n",
    "\n",
    "def num_to_char(nums, idx2word):\n",
    "    return [idx2word.get(num, '') for num in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aebac524-4ba4-4b05-961b-2962d9eb37ac",
    "_uuid": "15e76781-270b-4dbf-940e-7bc42c021c84",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.607302Z",
     "iopub.status.busy": "2024-11-18T07:38:41.606970Z",
     "iopub.status.idle": "2024-11-18T07:38:41.622916Z",
     "shell.execute_reply": "2024-11-18T07:38:41.622002Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.607270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LipDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, label_dir: str, vocab: list, word2idx: dict, idx2word: dict, transform=transforms.ToTensor()) -> None:\n",
    "        self.data_dir = data_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.data = os.listdir(data_dir)\n",
    "        self.data.remove('sgib8n.mpg.npy')  # Exclude problematic file if needed\n",
    "        self.label = os.listdir(label_dir)\n",
    "        self.vocab = vocab\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            data_path = os.path.join(self.data_dir, self.data[idx])\n",
    "            label_file = self.data[idx].split(\".\")[0] + \".align\"\n",
    "            label_path = os.path.join(self.label_dir, label_file)\n",
    "        \n",
    "\n",
    "            assert os.path.exists(data_path), f\"Data path {data_path} does not exist\"\n",
    "            assert os.path.exists(label_path), f\"Label path {label_path} does not exist\"\n",
    "\n",
    "            assert (\n",
    "                data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "                == label_path.split(\"/\")[-1].split(\".\")[0]\n",
    "            ), \"Data and label file names do not match\"\n",
    "\n",
    "            frames = self.load_video(data_path)\n",
    "            if frames is None:\n",
    "                print(idx)\n",
    "\n",
    "            label = self.load_alignment(label_path)\n",
    "\n",
    "            return frames, label\n",
    "        except Exception as e:\n",
    "            print(idx, e)\n",
    "\n",
    "    def get_data_name(self, idx):\n",
    "        return self.data[idx].split(\".\")[0]\n",
    "\n",
    "    def get_data_idx(self, name):\n",
    "        return self.data.index(name + \".mpg\")\n",
    "\n",
    "\n",
    "    def load_video(self, path: str) -> torch.Tensor:\n",
    "        np_frames = np.load(path)\n",
    "        frames = []\n",
    "        for i in np_frames:\n",
    "            frames.append(self.transform(i))\n",
    "            \n",
    "        frames = torch.stack(frames)\n",
    "        # Normalize frames (Z-score normalization)\n",
    "        \n",
    "        std = torch.std(frames)\n",
    "        mean = torch.mean(frames)\n",
    "        frames = (frames - mean) / std\n",
    "\n",
    "        return frames  # (T, C, H, W) format\n",
    "\n",
    "    def load_alignment(self, path: str) -> torch.Tensor:\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.readlines() \n",
    "        tokens = []\n",
    "        for line in lines:\n",
    "            line = line.split()\n",
    "            if line[2] != \"sil\":\n",
    "                tokens.append(' ')\n",
    "                tokens.extend(list(line[2]))  \n",
    "\n",
    "        token_nums = char_to_num(tokens, self.word2idx)\n",
    "        return torch.tensor(token_nums[1:], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88c053ed-e1e4-4454-ade5-5095b05518d9",
    "_uuid": "7b55be90-5d82-41c2-b4b4-f4be5e22725a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.624355Z",
     "iopub.status.busy": "2024-11-18T07:38:41.623972Z",
     "iopub.status.idle": "2024-11-18T07:38:41.833579Z",
     "shell.execute_reply": "2024-11-18T07:38:41.832716Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.624312Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = get_word2idx_idx2word(vocab)\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        # transforms.ToPILImage(),  \n",
    "        transforms.ToTensor(),    \n",
    "        # transforms.Resize((50, 100)),                   \n",
    "        # transforms.Normalize(mean=[0.7136, 0.4906, 0.3283], std=[0.1138, 0.1078, 0.0917]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_dir = \"/kaggle/input/lipnet-videos/lip_region/s1\"\n",
    "label_dir = \"/kaggle/input/lipnet-videos/alignments/s1\"\n",
    "\n",
    "dataset = LipDataset(data_dir, label_dir, transform=data_transform, vocab=vocab, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5392bde2-36e2-498c-a859-2c5550ce396d",
    "_uuid": "df44961e-eae2-4f96-a25c-20b75916cb1b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.835511Z",
     "iopub.status.busy": "2024-11-18T07:38:41.834871Z",
     "iopub.status.idle": "2024-11-18T07:38:41.841970Z",
     "shell.execute_reply": "2024-11-18T07:38:41.841091Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.835472Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    frames, labels = zip(*batch)\n",
    "\n",
    "    # Pad the frames to the same length\n",
    "    max_len = max([f.shape[0] for f in frames])\n",
    "    frames = [torch.nn.functional.pad(input=f, pad=(0, 0, 0, 0, 0, 0, 0, max_len - f.shape[0]), mode='constant', value=0) for f in frames] \n",
    "    \n",
    "\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "    \n",
    "    return torch.stack(frames), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6474634e-5963-4620-9c23-119fdda5d55f",
    "_uuid": "28a83ad7-8762-45ad-b8b8-f66a1ed6273a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.843747Z",
     "iopub.status.busy": "2024-11-18T07:38:41.843416Z",
     "iopub.status.idle": "2024-11-18T07:38:41.969740Z",
     "shell.execute_reply": "2024-11-18T07:38:41.968667Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.843713Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "frames, label = dataset[0]\n",
    "print(frames.shape, label, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "962ef637-8fd4-446a-a766-ca7c6ff3dd1b",
    "_uuid": "b3cbbad5-d670-438f-a294-d6c949b95c29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:41.971228Z",
     "iopub.status.busy": "2024-11-18T07:38:41.970886Z",
     "iopub.status.idle": "2024-11-18T07:38:42.234606Z",
     "shell.execute_reply": "2024-11-18T07:38:42.233615Z",
     "shell.execute_reply.started": "2024-11-18T07:38:41.971189Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(frames[41].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6611359-ae16-4899-b465-676171ed77a2",
    "_uuid": "50611a77-32e7-4450-9c88-d6d37e3d3cf3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.236218Z",
     "iopub.status.busy": "2024-11-18T07:38:42.235872Z",
     "iopub.status.idle": "2024-11-18T07:38:42.241484Z",
     "shell.execute_reply": "2024-11-18T07:38:42.240513Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.236182Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(''.join(num_to_char(label.tolist(), idx2word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ab74175-fc27-44b9-9ae5-22fee97ba14d",
    "_uuid": "3db6bd3c-5f3b-4d8a-a946-015ee3d6043c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.244868Z",
     "iopub.status.busy": "2024-11-18T07:38:42.244581Z",
     "iopub.status.idle": "2024-11-18T07:38:42.255610Z",
     "shell.execute_reply": "2024-11-18T07:38:42.254760Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.244836Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, val_split=0.1):\n",
    "    n_val = int(len(dataset) * val_split)\n",
    "    n_train = len(dataset) - n_val\n",
    "    return torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(dataset)\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.256963Z",
     "iopub.status.busy": "2024-11-18T07:38:42.256653Z",
     "iopub.status.idle": "2024-11-18T07:38:42.262975Z",
     "shell.execute_reply": "2024-11-18T07:38:42.262087Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.256932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=False, collate_fn=collate_fn, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "82d47a4c-86f4-4ae7-884d-a444c3925066",
    "_uuid": "4d94a07b-23a7-4ad8-80db-6961ad7782d3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.264575Z",
     "iopub.status.busy": "2024-11-18T07:38:42.264262Z",
     "iopub.status.idle": "2024-11-18T07:38:42.282342Z",
     "shell.execute_reply": "2024-11-18T07:38:42.281561Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.264543Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LipNet(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=128, dropout=0.4, input_channels=3):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=input_channels, out_channels=32, kernel_size=(3,5,5), stride=(1, 2, 2), padding=(1, 2, 2)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Dropout3d(dropout),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            \n",
    "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3,5,5), stride=(1, 1, 1), padding=(1, 2, 2)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Dropout3d(dropout),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            \n",
    "            \n",
    "            nn.Conv3d(in_channels=64, out_channels=96, kernel_size=(3,3,3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(96),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Dropout3d(dropout),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.rnn1 = nn.GRU(input_size= 96 * 3 * 6 , hidden_size=hidden_size,\n",
    "                             num_layers=1, batch_first=False, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.rnn2 = nn.GRU(input_size=hidden_size*2, hidden_size=hidden_size,\n",
    "                             num_layers=1, batch_first=False, bidirectional=True)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size+1)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.conv(x)\n",
    "        # print(x.shape)\n",
    "        x = x.permute(2, 0, 1, 3, 4).contiguous()\n",
    "        # (B, C, T, H, W)->(T, B, C*H*W)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        self.rnn1.flatten_parameters()\n",
    "        self.rnn2.flatten_parameters()\n",
    "        \n",
    "        x, _ = self.rnn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x, _ = self.rnn2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = x.permute(1, 0, 2).contiguous()\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.LSTM):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.orthogonal_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "        print('Model weights initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e880a1f-e84a-4d4b-9a66-74c23d167413",
    "_uuid": "94142783-9eee-4833-bdd4-97900800b284",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.284175Z",
     "iopub.status.busy": "2024-11-18T07:38:42.283549Z",
     "iopub.status.idle": "2024-11-18T07:38:42.550537Z",
     "shell.execute_reply": "2024-11-18T07:38:42.549691Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.284132Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " # deterministic training\n",
    "seed = 71\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "model = LipNet(vocab_size=len(vocab), input_channels=3, hidden_size=256).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe9ea195-7f70-45eb-b79b-e2870d650d73",
    "_uuid": "29007d49-d8bf-4aef-b724-ce4de85e1b7b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.551901Z",
     "iopub.status.busy": "2024-11-18T07:38:42.551626Z",
     "iopub.status.idle": "2024-11-18T07:38:42.556062Z",
     "shell.execute_reply": "2024-11-18T07:38:42.555098Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.551871Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# output = model(frames.permute(0,2,1,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45d43a1c-1edd-4aa1-bbfd-81c2999e5faf",
    "_uuid": "bded76dd-52e6-4627-b5b2-7cb2d73a6c2d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.557587Z",
     "iopub.status.busy": "2024-11-18T07:38:42.557250Z",
     "iopub.status.idle": "2024-11-18T07:38:42.564963Z",
     "shell.execute_reply": "2024-11-18T07:38:42.564258Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.557528Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ctc_greedy_decode(y_pred, idx2word, blank_index=0):\n",
    "    # Apply softmax to the model outputs to get probabilities\n",
    "    probs = F.softmax(y_pred, dim=-1)\n",
    "    \n",
    "    # Get the predicted classes by taking the argmax\n",
    "    predicted_indices = torch.argmax(probs, dim=-1)  # Shape: (batch_size, max_time)\n",
    "\n",
    "    # Now we will decode the indices into strings\n",
    "    decoded_outputs = []\n",
    "    for batch_idx in range(predicted_indices.size(0)):\n",
    "        current_output = []\n",
    "        previous_index = -1  # Initialize to -1 to not include blank at the start\n",
    "        \n",
    "        for time_step in range(predicted_indices.size(1)):\n",
    "            index = predicted_indices[batch_idx, time_step].item()\n",
    "            if index != blank_index and index != previous_index:\n",
    "                current_output.append(index)\n",
    "            previous_index = index\n",
    "        \n",
    "        decoded_outputs.append(current_output)  # Store decoded output for each batch\n",
    "    print(decoded_outputs)\n",
    "    return decoded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3eaeb12-60a9-422d-ac0f-47356a32abd2",
    "_uuid": "61b1a3a4-adf3-4a4d-89b8-6427e72c2806",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.566473Z",
     "iopub.status.busy": "2024-11-18T07:38:42.566171Z",
     "iopub.status.idle": "2024-11-18T07:38:42.574961Z",
     "shell.execute_reply": "2024-11-18T07:38:42.574281Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.566440Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "criterion = nn.CTCLoss(zero_infinity=True, blank = 0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "lambda_lr = lambda epoch: 1.0 if epoch < 30 else math.exp(-0.1 * (epoch - 29))\n",
    "# Use LambdaLR with your custom schedule\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c558c558-c41d-4e23-8523-1c44d68e4b15",
    "_uuid": "54df18ad-f245-499e-a816-39bf912842b2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.576313Z",
     "iopub.status.busy": "2024-11-18T07:38:42.575993Z",
     "iopub.status.idle": "2024-11-18T07:38:42.585760Z",
     "shell.execute_reply": "2024-11-18T07:38:42.584869Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.576282Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ctc_loss_fn(y_true, y_pred, ctc_loss):\n",
    "    batch_len = y_true.size(0)  # Number of sequences in the batch\n",
    "    input_length = y_pred.size(1)  # Time steps per batch sequence\n",
    "\n",
    "    input_lengths = torch.full((y_pred.size(0),), y_pred.size(1), dtype=torch.long).to(device)\n",
    "    target_lengths = torch.full((y_true.size(0),), y_true.size(1), dtype=torch.long).to(device)\n",
    "\n",
    "    # print(input_lengths, target_lengths, y_true.size(), y_pred.shape)\n",
    "    \n",
    "    y_preds_logits = y_pred.permute(1,0,2).log_softmax(dim=2)\n",
    "\n",
    "    loss = ctc_loss(y_preds_logits, y_true, input_lengths, target_lengths)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_path, min_loss, is_best=False):\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(checkpoint_path)):\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': loss,\n",
    "        'min_loss': min_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f'Checkpoint saved at {checkpoint_path}')\n",
    "    \n",
    "    if is_best:\n",
    "        best_path = checkpoint_path.replace('.pt', '_best.pt')\n",
    "        torch.save(checkpoint, best_path)\n",
    "        print(f'Best model saved at {best_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "718e0f51-2d61-4ea2-afcf-0e46a2111bf0",
    "_uuid": "1055163b-99ba-460f-aa3e-bbe8fee56ab3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.587134Z",
     "iopub.status.busy": "2024-11-18T07:38:42.586839Z",
     "iopub.status.idle": "2024-11-18T07:38:42.598844Z",
     "shell.execute_reply": "2024-11-18T07:38:42.597941Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.587104Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device, lr_scheduler,print_every=40):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, (frames, labels) in enumerate(dataloader):\n",
    "        frames, labels = frames.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        frames = frames.permute(0,2,1,3,4)\n",
    "        output = model(frames)\n",
    "        \n",
    "\n",
    "        loss = ctc_loss_fn(labels, output, criterion)\n",
    "         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        frames, labels = frames.cpu(), labels.cpu()\n",
    "        \n",
    "        if (i+1) % print_every == 0:\n",
    "            ctc_greedy_decode(output.clone(), idx2word)\n",
    "            print(f'Batch {i+1}/{len(dataloader)} - Loss: {loss.item()}')\n",
    "    \n",
    "    # lr_scheduler.step()\n",
    "    print(f'Learning rate: {lr_scheduler.get_last_lr()}')\n",
    "            \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, print_every=10):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for i, (frames, labels) in enumerate(dataloader):\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "            \n",
    "            output = model(frames.permute(0,2,1,3,4))\n",
    "             \n",
    "            loss = ctc_loss_fn(labels, output, criterion)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            frames, labels = frames.cpu(), labels.cpu()\n",
    "            \n",
    "            if (i+1) % print_every == 0:\n",
    "                ctc_greedy_decode(output.clone(), idx2word)\n",
    "                print(f'Batch {i+1}/{len(dataloader)} - Loss: {loss.item()}')\n",
    "                \n",
    "            \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "809ff5d3-3304-429f-b2fd-63a9aa97ca36",
    "_uuid": "f9c0f3eb-f733-40f1-96ba-6fc469bbe628",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:38:42.600216Z",
     "iopub.status.busy": "2024-11-18T07:38:42.599905Z",
     "iopub.status.idle": "2024-11-18T07:39:15.540136Z",
     "shell.execute_reply": "2024-11-18T07:39:15.538949Z",
     "shell.execute_reply.started": "2024-11-18T07:38:42.600176Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, lr_scheduler, num_epochs, device, checkpoint_path='/kaggle/working/check.pt', prev_checkpoint=None, new_lr = None ,  print_every=10):\n",
    "\n",
    "     \n",
    "    min_val_loss = float('inf')\n",
    "    start_epoch = 0\n",
    "\n",
    "    if prev_checkpoint is not None:\n",
    "        checkpoint = torch.load(prev_checkpoint)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        min_val_loss = checkpoint['min_loss']\n",
    "        print(f'Model loaded from checkpoint {prev_checkpoint}', start_epoch, \"Old Loss\", min_val_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"Old lr: \", param_group['lr'])\n",
    "            if new_lr:\n",
    "                param_group['lr'] = new_lr\n",
    "                print(\"New lr: \", param_group['lr'])\n",
    "   \n",
    "        \n",
    "    \n",
    "    loss_history = {'train': [], 'val': []}    \n",
    "    for epoch in tqdm(range(start_epoch, start_epoch+num_epochs)):\n",
    "        print(f'Epoch {epoch}/{start_epoch+num_epochs}')\n",
    "        \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, device, lr_scheduler, print_every)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        \n",
    "        val_loss = evaluate(model, val_dataloader, criterion, device, print_every)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss} - Val Loss: {val_loss}')\n",
    "        \n",
    "        min_val_loss = min(min_val_loss, val_loss)\n",
    "        \n",
    "        save_checkpoint(model, optimizer, epoch, val_loss, checkpoint_path, min_val_loss,is_best=(val_loss == min_val_loss))\n",
    "        \n",
    "    return loss_history\n",
    "\n",
    "num_epochs = 200\n",
    "prev_checkpoint= None #'/kaggle/input/lipnet/pytorch/try/1/check_best_2_1.pt' #'/kaggle/input/lipnet/pytorch/default/5/check_best3.pt'\n",
    "loss_history = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, lr_scheduler , num_epochs, device, prev_checkpoint = prev_checkpoint, new_lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cf3a5ebe-2fd4-4876-9c06-3795788cfa5b",
    "_uuid": "5ddf58ec-dce8-4d18-9e99-fe172732ac95",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:39:15.542134Z",
     "iopub.status.busy": "2024-11-18T07:39:15.541770Z",
     "iopub.status.idle": "2024-11-18T07:39:15.549327Z",
     "shell.execute_reply": "2024-11-18T07:39:15.548269Z",
     "shell.execute_reply.started": "2024-11-18T07:39:15.542092Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def try_model(model, dataloader):\n",
    "    model.eval()\n",
    "    frames, labels  = next(iter(dataloader))\n",
    "    frames = frames.permute(0,2,1,3,4).to(device)\n",
    "    output = model(frames)\n",
    "    frames = frames.cpu()\n",
    "    print('Output shape:', output.shape)\n",
    "    ctcts = ctc_greedy_decode(output, idx2word)\n",
    "    for (out, label)  in zip(ctcts, labels):\n",
    "        print(\"\".join(num_to_char(label.tolist(), idx2word)))\n",
    "        print(\"\".join(num_to_char(out, idx2word)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "63552a8f-5ac2-4a7d-a3e9-7531e5f18b4c",
    "_uuid": "79945823-c050-46f8-8ea5-564c55723931",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:39:15.551229Z",
     "iopub.status.busy": "2024-11-18T07:39:15.550576Z",
     "iopub.status.idle": "2024-11-18T07:39:16.392841Z",
     "shell.execute_reply": "2024-11-18T07:39:16.391732Z",
     "shell.execute_reply.started": "2024-11-18T07:39:15.551185Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try_model(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03636e06-8395-43b1-b5da-aa20b8b11c31",
    "_uuid": "adf116d0-e403-478e-beb6-3244fc0d1e29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-18T07:39:16.394712Z",
     "iopub.status.busy": "2024-11-18T07:39:16.394354Z",
     "iopub.status.idle": "2024-11-18T07:39:17.247306Z",
     "shell.execute_reply": "2024-11-18T07:39:17.246259Z",
     "shell.execute_reply.started": "2024-11-18T07:39:16.394673Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try_model(model, train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55e8bbb6-7cd7-44b4-b558-7fa09058659c",
    "_uuid": "9d0b6b8a-1029-45fd-8e10-83e94cbf57bc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T07:39:17.249028Z",
     "iopub.status.busy": "2024-11-18T07:39:17.248724Z",
     "iopub.status.idle": "2024-11-18T07:39:17.559434Z",
     "shell.execute_reply": "2024-11-18T07:39:17.558504Z",
     "shell.execute_reply.started": "2024-11-18T07:39:17.248993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history, title='Loss History', xlabel='Epochs', ylabel='Loss'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.plot(history['train'], label='Train Loss', color='blue', marker='o')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    plt.plot(history['val'], label='Validation Loss', color='orange', marker='o')\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5966387,
     "sourceId": 9938557,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 153909,
     "modelInstanceId": 131084,
     "sourceId": 158652,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
